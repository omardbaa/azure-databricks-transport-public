{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1704d965-044a-43a7-a28c-84462ea05dcd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Integrate and manage Public Transport data\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5cde7f9f-7ed5-4055-b72e-5aeb785e2764",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\n",
    "    f\"fs.azure.account.key.omardbstorageaccount.dfs.core.windows.net\", \n",
    "    \"G3TTTGHer5ZdNR78TdQvASgi9Mw+jDXH8Uk/6558WdDETLX3h3z/yGKvzS4YvfBL5ulvlBcVBvy/+ASt2O0TFA==\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e89b4339-8e19-4157-acb2-d16a67fa6e1d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Define the list of months and the number of days in each month\n",
    "months = [(\"January\", 31), (\"February\", 28), (\"March\", 31), (\"April\", 30), (\"May\", 31)]\n",
    "\n",
    "# Mounting data lake\n",
    "storageAccountName = \"omardbstorageaccount\"\n",
    "storageAccountAccessKey = \"G3TTTGHer5ZdNR78TdQvASgi9Mw+jDXH8Uk/6558WdDETLX3h3z/yGKvzS4YvfBL5ulvlBcVBvy/+ASt2O0TFA==\"\n",
    "sasToken = \"?sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupyx&se=2023-09-28T20:08:26Z&st=2023-09-26T12:08:26Z&spr=https&sig=7V6Sv9GschHeTzoMg80MHxy1kCl%2FPi7SnVDBozsYMTY%3D\"\n",
    "blobContainerName = \"public-transport-data\"\n",
    "mountPoint = \"/mnt/public-transport-data/\"\n",
    "\n",
    "\n",
    "if not any(mount.mountPoint == mountPoint for mount in dbutils.fs.mounts()):\n",
    "    try:\n",
    "        dbutils.fs.mount(\n",
    "            source=\"wasbs://{}@{}.blob.core.windows.net\".format(blobContainerName, storageAccountName),\n",
    "            mount_point=mountPoint,\n",
    "            extra_configs={'fs.azure.sas.' + blobContainerName + '.' + storageAccountName + '.blob.core.windows.net': sasToken}\n",
    "        )\n",
    "        print(\"Mount succeeded!\")\n",
    "    except Exception as e:\n",
    "        print(\"Mount exception:\", e)\n",
    "else:\n",
    "    print(\"Mount point already exists.\")\n",
    "\n",
    "# Generate data for each month\n",
    "for month_name, num_days in months:\n",
    "    # Generate data for the specific month\n",
    "    start_date = datetime(2023, months.index((month_name, num_days)) + 1, 1)\n",
    "    end_date = start_date + timedelta(days=num_days - 1)\n",
    "    date_generated = [start_date + timedelta(days=x) for x in range(0, num_days)]\n",
    "\n",
    "    transport_types = [\"Bus\", \"Train\", \"Tram\", \"Metro\"]\n",
    "    routes = [\"Route_\" + str(i) for i in range(1, 11)]\n",
    "    stations = [\"Station_\" + str(i) for i in range(1, 21)]\n",
    "\n",
    "    # Randomly select 5 days as extreme weather days\n",
    "    extreme_weather_days = random.sample(date_generated, 5)\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for date in date_generated:\n",
    "        for _ in range(32):  # 32 records per day to get a total of 992 records for each month\n",
    "            transport = random.choice(transport_types)\n",
    "            route = random.choice(routes)\n",
    "\n",
    "            # Normal operating hours\n",
    "            departure_hour = random.randint(5, 22)\n",
    "            departure_minute = random.randint(0, 59)\n",
    "\n",
    "            # Introducing Unusual Operating Hours for buses\n",
    "            if transport == \"Bus\" and random.random() < 0.05:  # 5% chance\n",
    "                departure_hour = 3\n",
    "\n",
    "            departure_time = f\"{departure_hour:02}:{departure_minute:02}\"\n",
    "\n",
    "            # Normal duration\n",
    "            duration = random.randint(10, 120)\n",
    "\n",
    "            # Introducing Short Turnarounds\n",
    "            if random.random() < 0.05:  # 5% chance\n",
    "                duration = random.randint(1, 5)\n",
    "\n",
    "            # General delay\n",
    "            delay = random.randint(0, 15)\n",
    "\n",
    "            # Weather Impact\n",
    "            if date in extreme_weather_days:\n",
    "                # Increase delay by 10 to 60 minutes\n",
    "                delay += random.randint(10, 60)\n",
    "\n",
    "                # 10% chance to change the route\n",
    "                if random.random() < 0.10:\n",
    "                    route = random.choice(routes)\n",
    "\n",
    "            total_minutes = departure_minute + duration + delay\n",
    "            arrival_hour = departure_hour + total_minutes // 60\n",
    "            arrival_minute = total_minutes % 60\n",
    "\n",
    "            # Ensure arrival times do not pass 24:59\n",
    "            if arrival_hour >= 24:\n",
    "                arrival_hour %= 24\n",
    "\n",
    "            arrival_time = f\"{arrival_hour:02}:{arrival_minute:02}\"\n",
    "\n",
    "            passengers = random.randint(1, 100)\n",
    "            departure_station = random.choice(stations)\n",
    "            arrival_station = random.choice(stations)\n",
    "\n",
    "            data.append([date, transport, route, departure_time, arrival_time, passengers, departure_station, arrival_station, delay])\n",
    "\n",
    "    # Create a Spark DataFrame from the data\n",
    "    df = spark.createDataFrame(data, schema=[\"Date\", \"TransportType\", \"Route\", \"DepartureTime\", \"ArrivalTime\", \"Passengers\", \"DepartureStation\", \"ArrivalStation\", \"Delay\"])\n",
    "    \n",
    "    # Save the DataFrame as a CSV file using the mount point\n",
    "    file_path = f\"/dbfs/mnt/public-transport-data/raw/public_transport_data_{month_name}.csv\"\n",
    "    data = df.toPandas()\n",
    "    data.to_csv(file_path, index=False)\n",
    "    print(\"done\")\n",
    "\n",
    "# Unmount the data lake\n",
    "dbutils.fs.unmount(mountPoint)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "public-transport-data-generator",
   "widgets": {}
  },
  "colab": {
   "authorship_tag": "ABX9TyNEcAPisy+UgH2pdAMa2tgd",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
