{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e43f2057-0e18-44dd-800b-9e8a83bb1c72",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9d430b9-6b2e-49ac-8e44-31a048d2e720",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90dd542f-1b4f-4135-a7ee-bf5bfc252de2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20d9e330-03cf-4a61-85c2-081296b55206",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Integrate and manage Public Transport data\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17244067-073b-4951-8cc1-af454f170bc3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\n",
    "    f\"fs.azure.account.key.omardbstorageaccount.dfs.core.windows.net\", \n",
    "    \"G3TTTGHer5ZdNR78TdQvASgi9Mw+jDXH8Uk/6558WdDETLX3h3z/yGKvzS4YvfBL5ulvlBcVBvy/+ASt2O0TFA==\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9578e21f-b8d5-4d93-833c-dca786acc115",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from pyspark.sql.functions import date_format, year, month, dayofmonth, dayofweek, unix_timestamp, when, col\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Define input and output directories in Data Lake Storage Gen2\n",
    "raw_data_dir = \"abfss://public-transport-data@omardbstorageaccount.dfs.core.windows.net/raw/\"\n",
    "processed_data_dir = \"abfss://public-transport-data@omardbstorageaccount.dfs.core.windows.net/processed/\"\n",
    "\n",
    "# List of months and corresponding file names\n",
    "months = [\"January\", \"February\", \"March\", \"April\", \"May\"]\n",
    "\n",
    "for month_name in months:\n",
    "    # Define input and output file paths\n",
    "    input_file = os.path.join(raw_data_dir, f\"public_transport_data_{month_name}.csv\")\n",
    "    output_file = os.path.join(processed_data_dir, f\"public_transport_data_{month_name}_cleaned.csv\")\n",
    "\n",
    "    # Read the data\n",
    "    df = spark.read.csv(input_file, header=True, inferSchema=True)\n",
    "\n",
    "    # Your data transformations here\n",
    "    # For example, convert \"ArrivalTime\" and \"DepartureTime\" to \"HH:mm\" format\n",
    "    df = df.withColumn(\"ArrivalTime\", date_format(df[\"ArrivalTime\"], \"HH:mm\"))\n",
    "    df = df.withColumn(\"DepartureTime\", date_format(df[\"DepartureTime\"], \"HH:mm\"))\n",
    "\n",
    "    # Add columns for Year, Month, Day, and DayOfWeek\n",
    "    df = df.withColumn(\"Year\", year(df[\"Date\"]))\n",
    "    df = df.withColumn(\"Month\", month(df[\"Date\"]))\n",
    "    df = df.withColumn(\"Day\", dayofmonth(df[\"Date\"]))\n",
    "    df = df.withColumn(\"DayOfWeek\", dayofweek(df[\"Date\"]))\n",
    "\n",
    "    # Convert DepartureTime and ArrivalTime columns to timestamp\n",
    "    df = df.withColumn(\"DepartureTimeTimestamp\", unix_timestamp(df[\"DepartureTime\"], \"HH:mm\").cast(\"timestamp\"))\n",
    "    df = df.withColumn(\"ArrivalTimeTimestamp\", unix_timestamp(df[\"ArrivalTime\"], \"HH:mm\").cast(\"timestamp\"))\n",
    "\n",
    "    # Calculate TripDuration in minutes and hours\n",
    "    df = df.withColumn(\"TripDurationMinutes\", \n",
    "        when(col(\"ArrivalTimeTimestamp\") >= col(\"DepartureTimeTimestamp\"), \n",
    "            (col(\"ArrivalTimeTimestamp\").cast(\"long\") - col(\"DepartureTimeTimestamp\").cast(\"long\")) / 60)\n",
    "        .otherwise(1440 - (col(\"DepartureTimeTimestamp\").cast(\"long\") - col(\"ArrivalTimeTimestamp\").cast(\"long\")) / 60))\n",
    "\n",
    "    # Drop the intermediate timestamp columns\n",
    "    df = df.drop(\"DepartureTimeTimestamp\", \"ArrivalTimeTimestamp\")\n",
    "\n",
    "    # Add DelayCategory column\n",
    "    df = df.withColumn(\"DelayCategory\", \n",
    "        when(col(\"Delay\") == 0, \"Pas de Retard\")\n",
    "        .when((col(\"Delay\") >= 1) & (col(\"Delay\") <= 10), \"Retard Court\")\n",
    "        .when((col(\"Delay\") >= 11) & (col(\"Delay\") <= 20), \"Retard Moyen\")\n",
    "        .when(col(\"Delay\") > 20, \"Long Retard\")\n",
    "        .otherwise(\"Unknown\"))\n",
    "\n",
    "    # Route analysis (you may need to define route_analysis DataFrame)\n",
    "    route_analysis = df.groupBy(\"Route\").agg(\n",
    "        F.round(F.avg(\"Delay\"), 2).alias(\"AverageDelay\"),\n",
    "        F.when((F.avg(\"Passengers\") % 1) >= 0.5, F.ceil(F.avg(\"Passengers\"))).otherwise(F.floor(F.avg(\"Passengers\"))).cast(\"int\").alias(\"AveragePassengers\"),\n",
    "        F.count(\"*\").alias(\"TotalTrips\")\n",
    "    )\n",
    "\n",
    "    df = df.join(route_analysis, on=\"Route\", how=\"left\")\n",
    "\n",
    "    # HeureDePointe column\n",
    "    threshold = 50\n",
    "    df = df.withColumn(\"HeureDePointe\", when(col(\"Passengers\") >= threshold, \"Peak\").otherwise(\"Off-Peak\"))\n",
    "\n",
    "    # Save the transformed DataFrame to the processed directory\n",
    "    df.write.option(\"header\", \"true\").csv(output_file)\n",
    "\n",
    "    # Pause execution for 2 minutes (120 seconds) before processing the next batch\n",
    "    time.sleep(120)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d190495d-198d-4c1c-8b5d-740d159c50d3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6585d1b1-1d0f-4403-8060-23bbe267cd44",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#file_location = \"abfss://public-transport-data@omardbstorageaccount.dfs.core.windows.net/raw/public_transport_data_January.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c7aab6c-9cd1-4350-93ee-bd00bc7c4e89",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67d91938-1e09-46d3-90ea-e64540aa2240",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#df = spark.read.format(\"csv\").option(\"inferSchema\", \"True\").option(\"header\",\n",
    "#\"True\").option(\"delimeter\",\",\").load(file_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f294ccd-26b1-4420-a1d2-55b0c4e35243",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74f2a532-a1a2-4f5b-ad39-f7ca0ffcd9ec",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d04d6010-623c-428d-95c3-ff0de4e63362",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "841318b8-cb67-432f-8d31-aa2c04745f2b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b6aec52-504d-42f4-a75c-7049b8a4064f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44ed1b31-affe-46fb-ac39-791cf2c0978e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "703afada-e13b-413e-96e8-de9284246b2f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b02ea19f-a9a7-4694-a4e0-a9515430e7b4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08d50289-cbd8-4292-85bc-8dd32529398c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d19839f6-317e-4d4c-8492-5bc3a95484dc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Join route-level statistics with the original DataFrame on the \"Route\" column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8eefe40-779c-4bd0-b962-b8ec5fbd1714",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#data = df.toPandas()\n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b912ccf2-2baf-4395-b21f-2118cd0967b7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a10ac603-9f62-432e-98da-3a46025356c2",
     "showTitle": false,
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the file location for export\n",
    "#file_location = \"abfss://publictransportdata@omardbstorageaccount.dfs.core.windows.net/processed/\"\n",
    "\n",
    "# Export the DataFrame to the specified location in CSV format\n",
    "#df.write.csv(file_location, header=True, mode=\"overwrite\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01559860-8161-4a9a-b054-bf81fc987413",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Reduce the number of output partitions to 1\n",
    "#df.repartition(1).write.option(\"header\", \"true\").csv(\"abfss://public-transport-data@omardbstorageaccount.dfs.core.windows.net/processed/public_transport_data_February_cleaned.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Public Transport",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
